{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Metrics:\n",
    "    @staticmethod\n",
    "    def k_fold_cross_validation(input_dataset, expected_output, k: int, df_columns: list = None):\n",
    "        if k <= 0 or k > len(input_dataset):\n",
    "            raise ValueError(\n",
    "                \"k must be greater than 0 and less than the number of rows in the dataset\")\n",
    "\n",
    "        if len(input_dataset) != len(expected_output):\n",
    "            raise ValueError(\n",
    "                \"The number of rows in the dataset must be equal to the number of rows in the expected output\")\n",
    "\n",
    "        # Shuffle the dataset\n",
    "        shuffled_tuple = list(zip(input_dataset, expected_output))\n",
    "        np.random.shuffle(shuffled_tuple)\n",
    "        shuffled_input_dataset, shuffled_expected_output = map(\n",
    "            np.array, zip(*shuffled_tuple))\n",
    "\n",
    "        items_per_fold = int(len(input_dataset) / k)\n",
    "        folds = []\n",
    "\n",
    "        print(shuffled_input_dataset[0:2])\n",
    "        print(\"============\")\n",
    "        print(shuffled_expected_output[0:2])\n",
    "\n",
    "        # Split the dataset into k folds\n",
    "        for i in range(k):\n",
    "            test_set = shuffled_input_dataset[i *\n",
    "                                     items_per_fold: (i + 1) * items_per_fold]\n",
    "            test_set_expected_output = shuffled_expected_output[i *\n",
    "                                                                items_per_fold: (i + 1) * items_per_fold]\n",
    "\n",
    "            train_set = np.concatenate(\n",
    "                [shuffled_input_dataset[:i * items_per_fold],\n",
    "                 shuffled_input_dataset[(i + 1) * items_per_fold:]])\n",
    "                \n",
    "            train_set_expected_output = np.concatenate(\n",
    "                [shuffled_expected_output[:i * items_per_fold],\n",
    "                 shuffled_expected_output[(i + 1) * items_per_fold:]])\n",
    "                \n",
    "            # If df_columns is not None, then we need to create a dataframe for both sets\n",
    "            if df_columns is not None:\n",
    "                train_set = pd.DataFrame(\n",
    "                    train_set, columns=df_columns)\n",
    "                test_set = pd.DataFrame(\n",
    "                    test_set, columns=df_columns)\n",
    "                train_set_expected_output = pd.DataFrame(\n",
    "                    train_set_expected_output, columns=['expected'])\n",
    "                test_set_expected_output = pd.DataFrame(\n",
    "                    test_set_expected_output, columns=['expected'])\n",
    "                \n",
    "            # Load the test and train sets into the folds\n",
    "            folds.append({\n",
    "                'train_set': train_set,\n",
    "                'test_set': test_set,\n",
    "                'train_set_expected_output': train_set_expected_output,\n",
    "                'test_set_expected_output': test_set_expected_output,\n",
    "            })\n",
    "\n",
    "\n",
    "        return folds\n",
    "\n",
    "    @staticmethod\n",
    "    def k_fold_cross_validation_eval(input_dataset, expected_output, model, k: int, df_columns: list = None):\n",
    "        if model is None:\n",
    "            raise ValueError(\"Model cannot be None\")\n",
    "\n",
    "        folds = Metrics.k_fold_cross_validation(\n",
    "            input_dataset, expected_output, k=k, df_columns=df_columns)\n",
    "\n",
    "        # Evaluate the model on each fold\n",
    "        results = []\n",
    "        for fold in folds:\n",
    "            # Train the model, on this case the expected output is present on the train set\n",
    "            # so ignore the train_set_expected_output field\n",
    "            train_set = fold['train_set']\n",
    "            model.train(train_set)\n",
    "\n",
    "            # Evaluate the model on the test set\n",
    "            test_set = fold['test_set']\n",
    "            results.append(model.test(test_set))\n",
    "\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesTextClassifier():\n",
    "    predicted_class_column_name = 'prediccion'\n",
    "\n",
    "    def __init__(self, classes, text_column_name, classes_column_name, tokenizer):\n",
    "        self.relative_frequencies = {}  # by_class_by_value\n",
    "        self.classes_probabilities = {}\n",
    "        self.classes = classes\n",
    "        self.classes_column_name = classes_column_name\n",
    "        self.text_column_name = text_column_name\n",
    "        self.row_count_by_class = {}\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def train(self, data_df):\n",
    "        for c in self.classes:\n",
    "            class_df = data_df[data_df[self.classes_column_name] == c]\n",
    "            self.row_count_by_class[c] = len(class_df)\n",
    "            self.classes_probabilities[c] = len(class_df) / len(data_df)\n",
    "\n",
    "            values_appearances = {}\n",
    "            # iterate over rows within class\n",
    "            for i in range(len(class_df)):\n",
    "                row = class_df.iloc[[i]]\n",
    "\n",
    "                tokenized_text = self.tokenizer(\n",
    "                    row[self.text_column_name].values[0])\n",
    "                # iterate over values within row\n",
    "                for token in tokenized_text:\n",
    "                    # initialize possible value if not present in map, otherwise increment appereances\n",
    "                    if token not in values_appearances:\n",
    "                        values_appearances[token] = 1\n",
    "                    else:\n",
    "                        values_appearances[token] += 1\n",
    "\n",
    "            # calculate relative frequencies\n",
    "            self.relative_frequencies[c] = {token: (token_count + 1) / (len(class_df) + len(\n",
    "                self.classes)) for token, token_count in values_appearances.items()}\n",
    "\n",
    "    def classify(self, sample):\n",
    "        tokenized_sample = self.tokenizer(sample)\n",
    "        classification = {}\n",
    "\n",
    "        maximizing_class = None\n",
    "        maximizing_prod = -1\n",
    "        for c in self.classes:\n",
    "\n",
    "            prod = self.classes_probabilities[c]\n",
    "            token_likelihoods = self.relative_frequencies[c]\n",
    "            laplace_constant = 1 / \\\n",
    "                (self.row_count_by_class[c] + len(self.classes))\n",
    "\n",
    "            for token in tokenized_sample:\n",
    "                prod *= token_likelihoods[token] if token in token_likelihoods else laplace_constant\n",
    "\n",
    "            classification[c] = prod\n",
    "\n",
    "        return dict(sorted(classification.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    def test(self, test_df):\n",
    "        predicted_classes = []\n",
    "\n",
    "        for i in range(len(test_df)):\n",
    "            row = test_df.iloc[[i]]\n",
    "            row_class = row[self.classes_column_name].values[0] \n",
    "\n",
    "            classification = self.classify(row[self.text_column_name].values[0])\n",
    "            predicted_class = max(classification, key=classification.get)\n",
    "\n",
    "            predicted_classes.append(predicted_class)\n",
    "\n",
    "        # append results column to new dataframe\n",
    "        results_df = test_df.copy()\n",
    "        results_df[self.predicted_class_column_name] = predicted_classes\n",
    "        \n",
    "        return results_df\n",
    "        \n",
    "    def get_confusion_matrix(self):\n",
    "        pass\n",
    "\n",
    "    def get_evaluation_metrics_by_class(self, test_results_df):\n",
    "        pass\n",
    "\n",
    "    def plot_roc_curve(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str):\n",
    "    return text.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"./Noticias_argentinas.txt\", header=0, sep='\\t')\n",
    "classes = [\"Economia\", \"Salud\", \"Ciencia y Tecnologia\", \"Deportes\"]\n",
    "\n",
    "data_df = data_df[data_df[\"categoria\"].isin(classes)]\n",
    "\n",
    "\n",
    "nbclassifier = NaiveBayesTextClassifier(\n",
    "    classes, \"titular\", \"categoria\", tokenize)\n",
    "# Get expected output for dataset\n",
    "expected_output = data_df[\"categoria\"]\n",
    "print(len(expected_output))\n",
    "# print(\"Expected output: \", expected_output)\n",
    "print(Metrics.k_fold_cross_validation_eval(data_df.values.tolist(), expected_output.values.tolist(), model=nbclassifier,df_columns=data_df.columns, k=2))\n",
    "\n",
    "# train_set = data_df.sample(frac=0.8, random_state=1)\n",
    "# print(\"======================\")\n",
    "# print(train_set.index)\n",
    "# test_set = data_df.drop(train_set.index)\n",
    "\n",
    "# nbclassifier.train(train_set)\n",
    "# print(nbclassifier.test(test_set))\n",
    "\n",
    "# sample_columns = data_df.columns.drop(\"categoria\")\n",
    "\n",
    "# print(nbclassifier.classify(\"Histórico: Los Pumas derrotaron por primera vez a los All Blacks en Nueva Zelanda\"))\n",
    "# print(nbclassifier.classify(\"Maradona negó haber criticado a Messi, disparó otra vez contra Scaloni y también la ligó Solari\"))\n",
    "# print(nbclassifier.classify(\"Guzmán\"))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "964b1fa5364468aa142ca826e1bab4686480a96d9d38c308c84d42c2ef7b8b78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
