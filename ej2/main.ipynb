{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Metrics:\n",
    "    @staticmethod\n",
    "    def k_fold_cross_validation(x, y, k: int, x_column_names: list = None, y_column_names: list = None):\n",
    "        if k <= 0 or k > len(x):\n",
    "            raise ValueError(\n",
    "                \"k must be greater than 0 and less than the number of rows in the dataset\")\n",
    "\n",
    "        if len(x) != len(y):\n",
    "            raise ValueError(\n",
    "                \"The number of rows in the dataset must be equal to the number of rows in the expected output\")\n",
    "\n",
    "        # Shuffle the dataset\n",
    "        shuffled_dataset = list(zip(x, y))\n",
    "        np.random.shuffle(shuffled_dataset)\n",
    "        x, y = map(\n",
    "            np.array, zip(*shuffled_dataset))\n",
    "\n",
    "        fold_len = int(len(x) / k)\n",
    "        folds = []\n",
    "\n",
    "        print(x[0:2])\n",
    "        print(\"============\")\n",
    "        print(y[0:2])\n",
    "\n",
    "        # Split the dataset into k folds\n",
    "        for i in range(k):\n",
    "            x_test = x[i *\n",
    "                       fold_len: (i + 1) * fold_len]\n",
    "            y_test = y[i *\n",
    "                       fold_len: (i + 1) * fold_len]\n",
    "\n",
    "            x_train = np.concatenate(\n",
    "                [x[:i * fold_len],\n",
    "                 x[(i + 1) * fold_len:]])\n",
    "\n",
    "            y_train = np.concatenate(\n",
    "                [y[:i * fold_len],\n",
    "                 y[(i + 1) * fold_len:]])\n",
    "\n",
    "            # If df_columns is not None, then we need to create a dataframe for both sets\n",
    "            if x_column_names is not None:\n",
    "                x_train = pd.DataFrame(\n",
    "                    x_train, columns=x_column_names)\n",
    "                x_test = pd.DataFrame(\n",
    "                    x_test, columns=x_column_names)\n",
    "                y_train = pd.DataFrame(\n",
    "                    y_train, columns=y_column_names)\n",
    "                y_test = pd.DataFrame(\n",
    "                    y_test, columns=y_column_names)\n",
    "\n",
    "            # Load the test and train sets into the folds\n",
    "            folds.append({\n",
    "                'x_train': x_train,\n",
    "                'y_train': y_train,\n",
    "                'x_test': x_test,\n",
    "                'y_test': y_test,\n",
    "            })\n",
    "\n",
    "        return folds\n",
    "\n",
    "    @staticmethod\n",
    "    def k_fold_cross_validation_eval(x, y, model, k: int, x_column_names: list = None, y_column_names: list = None):\n",
    "        if model is None:\n",
    "            raise ValueError(\"Model cannot be None\")\n",
    "\n",
    "        folds = Metrics.k_fold_cross_validation(\n",
    "            x, y, k=k, x_column_names=x_column_names, y_column_names=y_column_names)\n",
    "\n",
    "        # Evaluate the model on each fold\n",
    "        results = []\n",
    "        for fold in folds:\n",
    "            # Train the model, on this case the expected output is present on the train set\n",
    "            # so ignore the train_set_expected_output field\n",
    "            x_train = fold['x_train']\n",
    "            y_train = fold['y_train']\n",
    "            model.train(pd.concat([x_train, y_train], axis=1))\n",
    "\n",
    "            # Evaluate the model on the test set\n",
    "            x_test = fold['x_test']\n",
    "            y_test = fold['y_test']\n",
    "            results.append(model.test(pd.concat([x_test, y_test], axis=1)))\n",
    "\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesTextClassifier():\n",
    "    predicted_class_column_name = 'prediccion'\n",
    "\n",
    "    def __init__(self, classes, text_column_name, classes_column_name, tokenizer):\n",
    "        self.relative_frequencies = {}  # by_class_by_value\n",
    "        self.classes_probabilities = {}\n",
    "        self.classes = classes\n",
    "        self.classes_column_name = classes_column_name\n",
    "        self.text_column_name = text_column_name\n",
    "        self.row_count_by_class = {}\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def train(self, data_df):\n",
    "        for c in self.classes:\n",
    "            class_df = data_df[data_df[self.classes_column_name] == c]\n",
    "            self.row_count_by_class[c] = len(class_df)\n",
    "            self.classes_probabilities[c] = len(class_df) / len(data_df)\n",
    "\n",
    "            values_appearances = {}\n",
    "            # iterate over rows within class\n",
    "            for i in range(len(class_df)):\n",
    "                row = class_df.iloc[[i]]\n",
    "\n",
    "                tokenized_text = self.tokenizer(\n",
    "                    row[self.text_column_name].values[0])\n",
    "                # iterate over values within row\n",
    "                for token in tokenized_text:\n",
    "                    # initialize possible value if not present in map, otherwise increment appereances\n",
    "                    if token not in values_appearances:\n",
    "                        values_appearances[token] = 1\n",
    "                    else:\n",
    "                        values_appearances[token] += 1\n",
    "\n",
    "            # calculate relative frequencies\n",
    "            self.relative_frequencies[c] = {token: (token_count + 1) / (len(class_df) + len(\n",
    "                self.classes)) for token, token_count in values_appearances.items()}\n",
    "\n",
    "    def classify(self, sample):\n",
    "        tokenized_sample = self.tokenizer(sample)\n",
    "        classification = {}\n",
    "\n",
    "        maximizing_class = None\n",
    "        maximizing_prod = -1\n",
    "        for c in self.classes:\n",
    "\n",
    "            prod = self.classes_probabilities[c]\n",
    "            token_likelihoods = self.relative_frequencies[c]\n",
    "            laplace_constant = 1 / \\\n",
    "                (self.row_count_by_class[c] + len(self.classes))\n",
    "\n",
    "            for token in tokenized_sample:\n",
    "                prod *= token_likelihoods[token] if token in token_likelihoods else laplace_constant\n",
    "\n",
    "            classification[c] = prod\n",
    "\n",
    "        return dict(sorted(classification.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    def test(self, test_df):\n",
    "        predicted_classes = []\n",
    "\n",
    "        for i in range(len(test_df)):\n",
    "            row = test_df.iloc[[i]]\n",
    "            row_class = row[self.classes_column_name].values[0]\n",
    "\n",
    "            classification = self.classify(\n",
    "                row[self.text_column_name].values[0])\n",
    "            predicted_class = max(classification, key=classification.get)\n",
    "\n",
    "            predicted_classes.append(predicted_class)\n",
    "\n",
    "        # append results column to new dataframe\n",
    "        results_df = test_df.copy()\n",
    "        results_df[self.predicted_class_column_name] = predicted_classes\n",
    "\n",
    "        return results_df\n",
    "\n",
    "    def get_confusion_matrix(self):\n",
    "        pass\n",
    "\n",
    "    def get_evaluation_metrics_by_class(self, test_results_df):\n",
    "        pass\n",
    "\n",
    "    def plot_roc_curve(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str):\n",
    "    return text.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15406\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/gonzaloarca/ITBA/ml/machine-learning/ej2/main.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gonzaloarca/ITBA/ml/machine-learning/ej2/main.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(y))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gonzaloarca/ITBA/ml/machine-learning/ej2/main.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# print(\"Expected output: \", expected_output)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gonzaloarca/ITBA/ml/machine-learning/ej2/main.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(Metrics\u001b[39m.\u001b[39mk_fold_cross_validation_eval(x\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist(), y\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist(\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gonzaloarca/ITBA/ml/machine-learning/ej2/main.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m ), model\u001b[39m=\u001b[39mnbclassifier, x_column_names\u001b[39m=\u001b[39mx\u001b[39m.\u001b[39;49mcolumns, y_column_names\u001b[39m=\u001b[39my\u001b[39m.\u001b[39mcolumns, k\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m))\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5568\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   5569\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   5570\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   5571\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   5572\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5573\u001b[0m ):\n\u001b[1;32m   5574\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> 5575\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"./Noticias_argentinas.txt\", header=0, sep='\\t')\n",
    "classes = [\"Economia\", \"Salud\", \"Ciencia y Tecnologia\", \"Deportes\"]\n",
    "\n",
    "data_df = data_df[data_df[\"categoria\"].isin(classes)]\n",
    "\n",
    "\n",
    "nbclassifier = NaiveBayesTextClassifier(\n",
    "    classes, \"titular\", \"categoria\", tokenize)\n",
    "# Get expected output for dataset\n",
    "\n",
    "y = data_df.loc[:, [\"categoria\"]]\n",
    "x = data_df.loc[:, [\"titular\"]]\n",
    "print(len(y))\n",
    "# print(\"Expected output: \", expected_output)\n",
    "print(Metrics.k_fold_cross_validation_eval(x.values.tolist(), y.values.tolist(\n",
    "), model=nbclassifier, x_column_names=x.columns, y_column_names=y.columns, k=2))\n",
    "\n",
    "# train_set = data_df.sample(frac=0.8, random_state=1)\n",
    "# print(\"======================\")\n",
    "# print(train_set.index)\n",
    "# test_set = data_df.drop(train_set.index)\n",
    "\n",
    "# nbclassifier.train(train_set)\n",
    "# print(nbclassifier.test(test_set))\n",
    "\n",
    "# sample_columns = data_df.columns.drop(\"categoria\")\n",
    "\n",
    "# print(nbclassifier.classify(\"Histórico: Los Pumas derrotaron por primera vez a los All Blacks en Nueva Zelanda\"))\n",
    "# print(nbclassifier.classify(\"Maradona negó haber criticado a Messi, disparó otra vez contra Scaloni y también la ligó Solari\"))\n",
    "# print(nbclassifier.classify(\"Guzmán\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
