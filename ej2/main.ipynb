{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesTextClassifier:\n",
    "\n",
    "    def __init__(self, classes, text_column_name, classes_column_name, tokenizer):\n",
    "        self.relative_frequencies = {}  # by_class_by_value\n",
    "        self.classes_probabilities = {}\n",
    "        self.classes = classes\n",
    "        self.classes_column_name = classes_column_name\n",
    "        self.text_column_name = text_column_name\n",
    "        self.row_count_by_class = {}\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def train(self, data_df):\n",
    "        for c in self.classes:\n",
    "            class_df = data_df[data_df[self.classes_column_name] == c]\n",
    "            self.row_count_by_class[c] = len(class_df)\n",
    "            self.classes_probabilities[c] = len(class_df) / len(data_df)\n",
    "\n",
    "            values_appearances = {}\n",
    "            # iterate over rows within class\n",
    "            for i in range(len(class_df)):\n",
    "                row = class_df.iloc[[i]]\n",
    "\n",
    "                tokenized_text = self.tokenizer(\n",
    "                    row[self.text_column_name].values[0])\n",
    "                # iterate over values within row\n",
    "                for token in tokenized_text:\n",
    "                    # initialize possible value if not present in map, otherwise increment appereances\n",
    "                    if token not in values_appearances:\n",
    "                        values_appearances[token] = 1\n",
    "                    else:\n",
    "                        values_appearances[token] += 1\n",
    "\n",
    "            # calculate relative frequencies\n",
    "            self.relative_frequencies[c] = {token: (token_count + 1) / (len(class_df) + len(\n",
    "                self.classes)) for token, token_count in values_appearances.items()}\n",
    "\n",
    "\n",
    "    def classify(self, sample):\n",
    "        tokenized_sample = self.tokenizer(sample)\n",
    "        classification = {}\n",
    "\n",
    "        maximizing_class = None\n",
    "        maximizing_prod = -1\n",
    "        for c in self.classes:\n",
    "\n",
    "            prod = self.classes_probabilities[c]\n",
    "            token_likelihoods = self.relative_frequencies[c]\n",
    "            laplace_constant = 1 / \\\n",
    "                (self.row_count_by_class[c] + len(self.classes))\n",
    "\n",
    "            for token in tokenized_sample:\n",
    "                prod *= token_likelihoods[token] if token in token_likelihoods else laplace_constant\n",
    "\n",
    "            classification[c] = prod\n",
    "\n",
    "        return dict(sorted(classification.items(), key=lambda item: item[1], reverse=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str):\n",
    "    return text.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Deportes': 1.0923717845242864e-31, 'Economia': 2.3878352702903526e-33, 'Ciencia y Tecnologia': 2.0081003185176624e-34, 'Salud': 8.598773060888454e-36}\n",
      "{'Deportes': 3.582880382438505e-33, 'Economia': 3.16071890106868e-42, 'Ciencia y Tecnologia': 2.575323374214025e-43, 'Salud': 4.424901195844235e-44}\n",
      "{'Deportes': 6.484258102769242e-05, 'Ciencia y Tecnologia': 6.484251139620591e-05, 'Economia': 6.484240667796619e-05, 'Salud': 6.484223142111342e-05}\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"./Noticias_argentinas.txt\", header=0, sep='\\t')\n",
    "classes = [\"Economia\", \"Salud\", \"Ciencia y Tecnologia\", \"Deportes\"]\n",
    "\n",
    "data_df = data_df[data_df[\"categoria\"].isin(classes)]\n",
    "\n",
    "\n",
    "nbclassifier = NaiveBayesTextClassifier(\n",
    "    classes, \"titular\", \"categoria\", tokenize)\n",
    "nbclassifier.train(data_df)\n",
    "\n",
    "sample_columns = data_df.columns.drop(\"categoria\")\n",
    "\n",
    "print(nbclassifier.classify(\"Histórico: Los Pumas derrotaron por primera vez a los All Blacks en Nueva Zelanda\"))\n",
    "print(nbclassifier.classify(\"Maradona negó haber criticado a Messi, disparó otra vez contra Scaloni y también la ligó Solari\"))\n",
    "print(nbclassifier.classify(\"Guzmán\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
