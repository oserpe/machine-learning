{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesTextClassifier:\n",
    "    predicted_class_column_name = 'prediccion'\n",
    "\n",
    "    def __init__(self, classes, text_column_name, classes_column_name, tokenizer):\n",
    "        self.relative_frequencies = {}  # by_class_by_value\n",
    "        self.classes_probabilities = {}\n",
    "        self.classes = classes\n",
    "        self.classes_column_name = classes_column_name\n",
    "        self.text_column_name = text_column_name\n",
    "        self.row_count_by_class = {}\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def train(self, data_df):\n",
    "        for c in self.classes:\n",
    "            class_df = data_df[data_df[self.classes_column_name] == c]\n",
    "            self.row_count_by_class[c] = len(class_df)\n",
    "            self.classes_probabilities[c] = len(class_df) / len(data_df)\n",
    "\n",
    "            values_appearances = {}\n",
    "            # iterate over rows within class\n",
    "            for i in range(len(class_df)):\n",
    "                row = class_df.iloc[[i]]\n",
    "\n",
    "                tokenized_text = self.tokenizer(\n",
    "                    row[self.text_column_name].values[0])\n",
    "                # iterate over values within row\n",
    "                for token in tokenized_text:\n",
    "                    # initialize possible value if not present in map, otherwise increment appereances\n",
    "                    if token not in values_appearances:\n",
    "                        values_appearances[token] = 1\n",
    "                    else:\n",
    "                        values_appearances[token] += 1\n",
    "\n",
    "            # calculate relative frequencies\n",
    "            self.relative_frequencies[c] = {token: (token_count + 1) / (len(class_df) + len(\n",
    "                self.classes)) for token, token_count in values_appearances.items()}\n",
    "\n",
    "    def classify(self, sample):\n",
    "        tokenized_sample = self.tokenizer(sample)\n",
    "        classification = {}\n",
    "\n",
    "        maximizing_class = None\n",
    "        maximizing_prod = -1\n",
    "        for c in self.classes:\n",
    "\n",
    "            prod = self.classes_probabilities[c]\n",
    "            token_likelihoods = self.relative_frequencies[c]\n",
    "            laplace_constant = 1 / \\\n",
    "                (self.row_count_by_class[c] + len(self.classes))\n",
    "\n",
    "            for token in tokenized_sample:\n",
    "                prod *= token_likelihoods[token] if token in token_likelihoods else laplace_constant\n",
    "\n",
    "            classification[c] = prod\n",
    "\n",
    "        return dict(sorted(classification.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    def test(self, test_df):\n",
    "        predicted_classes = []\n",
    "\n",
    "        for i in range(len(test_df)):\n",
    "            row = test_df.iloc[[i]]\n",
    "            row_class = row[self.classes_column_name].values[0] \n",
    "\n",
    "            classification = self.classify(row[self.text_column_name].values[0])\n",
    "            predicted_class = max(classification, key=classification.get)\n",
    "\n",
    "            predicted_classes.append(predicted_class)\n",
    "\n",
    "        # append results column to new dataframe\n",
    "        results_df = test_df.copy()\n",
    "        results_df[self.predicted_class_column_name] = predicted_classes\n",
    "        \n",
    "        return results_df\n",
    "        \n",
    "    def get_confusion_matrix(self):\n",
    "        pass\n",
    "\n",
    "    def get_evaluation_metrics_by_class(self, test_results_df):\n",
    "        pass\n",
    "\n",
    "    def plot_roc_curve(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str):\n",
    "    return text.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  fecha                                            titular  \\\n",
      "20     11/14/2018 10:44  Superclásico: River sacó a la venta más entrad...   \n",
      "22      11/14/2018 9:36  Maradona negó haber criticado a Messi, disparó...   \n",
      "35      11/14/2018 7:52  En lo que va del año, Iosper invirtió 160.000....   \n",
      "38     11/14/2018 10:19  ¿Un milagro? el tumor cerebra de una paciente ...   \n",
      "40     11/13/2018 22:09  Cómo hacer para recuperar un mensaje de Whatsa...   \n",
      "...                 ...                                                ...   \n",
      "30796   12/5/2018 16:48  Autorizaron a viajar a Madrid a Rafael Di Zeo,...   \n",
      "30802   12/5/2018 17:35  El rival de Rafael Di Zeo por el comando de \"L...   \n",
      "30806   12/5/2018 14:39  Nos dio mucha alegría ver nacer al primer bebé...   \n",
      "30818    12/5/2018 8:31  El Galaxy S10 de Samsung contará con 4 cámaras...   \n",
      "30823   12/5/2018 17:20      Tumblr prohibirá los contenidos pornográficos   \n",
      "\n",
      "                            fuente             categoria  \\\n",
      "20     Diario ElSol.com.ar Mendoza              Deportes   \n",
      "22                      Ambito.com              Deportes   \n",
      "35                     AIM Digital                 Salud   \n",
      "38               El Tribuno.com.ar                 Salud   \n",
      "40               El Tribuno.com.ar  Ciencia y Tecnologia   \n",
      "...                            ...                   ...   \n",
      "30796                   Clarín.com              Deportes   \n",
      "30802                  Infobae.com              Deportes   \n",
      "30806                  Infobae.com                 Salud   \n",
      "30818  Diario ElSol.com.ar Mendoza  Ciencia y Tecnologia   \n",
      "30823                  CasildaPlus  Ciencia y Tecnologia   \n",
      "\n",
      "      predicted_class_column_name  \n",
      "20                       Deportes  \n",
      "22                       Deportes  \n",
      "35                       Economia  \n",
      "38                          Salud  \n",
      "40           Ciencia y Tecnologia  \n",
      "...                           ...  \n",
      "30796                    Deportes  \n",
      "30802                    Deportes  \n",
      "30806                       Salud  \n",
      "30818        Ciencia y Tecnologia  \n",
      "30823        Ciencia y Tecnologia  \n",
      "\n",
      "[3081 rows x 5 columns]\n",
      "{'Deportes': 1.626854889107265e-31, 'Economia': 7.164375425556349e-33, 'Ciencia y Tecnologia': 6.753280131577993e-34, 'Salud': 3.734637216936557e-35}\n",
      "{'Deportes': 4.215402157964184e-34, 'Economia': 1.1664439221006085e-41, 'Ciencia y Tecnologia': 1.7464701752688814e-42, 'Salud': 3.610442176979137e-43}\n",
      "{'Salud': 8.103127864899044e-05, 'Ciencia y Tecnologia': 8.103114356314418e-05, 'Deportes': 8.10310420196155e-05, 'Economia': 8.102935516135948e-05}\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"./Noticias_argentinas.txt\", header=0, sep='\\t')\n",
    "classes = [\"Economia\", \"Salud\", \"Ciencia y Tecnologia\", \"Deportes\"]\n",
    "\n",
    "data_df = data_df[data_df[\"categoria\"].isin(classes)]\n",
    "\n",
    "\n",
    "nbclassifier = NaiveBayesTextClassifier(\n",
    "    classes, \"titular\", \"categoria\", tokenize)\n",
    "\n",
    "train_set = data_df.sample(frac=0.8, random_state=1)\n",
    "test_set = data_df.drop(train_set.index)\n",
    "\n",
    "nbclassifier.train(train_set)\n",
    "print(nbclassifier.test(test_set))\n",
    "\n",
    "sample_columns = data_df.columns.drop(\"categoria\")\n",
    "\n",
    "print(nbclassifier.classify(\"Histórico: Los Pumas derrotaron por primera vez a los All Blacks en Nueva Zelanda\"))\n",
    "print(nbclassifier.classify(\"Maradona negó haber criticado a Messi, disparó otra vez contra Scaloni y también la ligó Solari\"))\n",
    "print(nbclassifier.classify(\"Guzmán\"))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
