{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "from sklearn.metrics import confusion_matrix, auc\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    @staticmethod\n",
    "    def k_fold_cross_validation(x, y, k: int, x_column_names: list = None, y_column_names: list = None, folds_to_return: int = None):\n",
    "        if k <= 0 or k > len(x):\n",
    "            raise ValueError(\n",
    "                \"k must be greater than 0 and less than the number of rows in the dataset\")\n",
    "\n",
    "        if len(x) != len(y):\n",
    "            raise ValueError(\n",
    "                \"The number of rows in the dataset must be equal to the number of rows in the expected output\")\n",
    "\n",
    "        if folds_to_return is None:\n",
    "            folds_to_return = k\n",
    "\n",
    "        # Shuffle the dataset\n",
    "        shuffled_dataset = list(zip(x, y))\n",
    "        np.random.shuffle(shuffled_dataset)\n",
    "        x, y = map(\n",
    "            np.array, zip(*shuffled_dataset))\n",
    "\n",
    "        fold_len = int(len(x) / k)\n",
    "        folds = []\n",
    "\n",
    "        # Split the dataset into k folds\n",
    "        # Maybe we want less folds than k\n",
    "        for i in range(min(k, folds_to_return)):\n",
    "            x_test = x[i *\n",
    "                       fold_len: (i + 1) * fold_len]\n",
    "            y_test = y[i *\n",
    "                       fold_len: (i + 1) * fold_len]\n",
    "\n",
    "            x_train = np.concatenate(\n",
    "                [x[:i * fold_len],\n",
    "                 x[(i + 1) * fold_len:]])\n",
    "\n",
    "            y_train = np.concatenate(\n",
    "                [y[:i * fold_len],\n",
    "                 y[(i + 1) * fold_len:]])\n",
    "\n",
    "            # If df_columns is not None, then we need to create a dataframe for both sets\n",
    "            if x_column_names is not None:\n",
    "                x_train = pd.DataFrame(\n",
    "                    x_train, columns=x_column_names)\n",
    "                x_test = pd.DataFrame(\n",
    "                    x_test, columns=x_column_names)\n",
    "                y_train = pd.DataFrame(\n",
    "                    y_train, columns=y_column_names)\n",
    "                y_test = pd.DataFrame(\n",
    "                    y_test, columns=y_column_names)\n",
    "\n",
    "            # Load the test and train sets into the folds\n",
    "            folds.append({\n",
    "                'x_train': x_train,\n",
    "                'y_train': y_train,\n",
    "                'x_test': x_test,\n",
    "                'y_test': y_test,\n",
    "            })\n",
    "\n",
    "        return folds\n",
    "\n",
    "    @staticmethod\n",
    "    def k_fold_cross_validation_eval(x, y, model, k: int, x_column_names: list = None, y_column_names: list = None):\n",
    "        if model is None:\n",
    "            raise ValueError(\"Model cannot be None\")\n",
    "\n",
    "        folds = Metrics.k_fold_cross_validation(\n",
    "            x, y, k=k, x_column_names=x_column_names, y_column_names=y_column_names)\n",
    "\n",
    "        # Evaluate the model on each fold\n",
    "        results = []\n",
    "        errors = []\n",
    "        k_metrics_per_class = {\n",
    "            'accuracy': {label: [] for label in model.classes},\n",
    "            'precision': {label: [] for label in model.classes},\n",
    "            'recall': {label: [] for label in model.classes},\n",
    "            'f1-score': {label: [] for label in model.classes},\n",
    "            'tp-rate': {label: [] for label in model.classes},\n",
    "            'fp-rate': {label: [] for label in model.classes},\n",
    "        }\n",
    "\n",
    "        for fold in folds:\n",
    "            # Train the model\n",
    "            x_train = fold['x_train']\n",
    "            y_train = fold['y_train']\n",
    "            model.train(pd.concat([x_train, y_train], axis=1))\n",
    "\n",
    "            # Evaluate the model on the test set\n",
    "            x_test = fold['x_test']\n",
    "            y_test = fold['y_test']\n",
    "            predictions = model.test(pd.concat([x_test, y_test], axis=1))\n",
    "\n",
    "            # Compute the metrics\n",
    "            cf_matrix = Metrics.get_confusion_matrix(\n",
    "                predictions[model.classes_column_name].values.tolist(), predictions[model.predicted_class_column_name].values.tolist(), labels=model.classes)\n",
    "            \n",
    "            metrics_df = Metrics.get_metrics_per_class(cf_matrix)[1]\n",
    "\n",
    "            # Push the metrics to the total metrics\n",
    "            for metric_label in k_metrics_per_class:\n",
    "                for label in model.classes:\n",
    "                    k_metrics_per_class[metric_label][label].append(metrics_df[metric_label][label])\n",
    "\n",
    "            results.append(predictions)\n",
    "            errors.append(Metrics.error(predictions, y_test,\n",
    "                          uses_df=x_column_names is not None))\n",
    "\n",
    "        # Compute the average and standard deviation metrics\n",
    "        average_metrics = {metric_label: {label: np.mean(k_metrics_per_class[metric_label][label]) for label in model.classes} for metric_label in k_metrics_per_class}\n",
    "        std_metrics = {metric_label: {label: np.std(k_metrics_per_class[metric_label][label]) for label in model.classes} for metric_label in k_metrics_per_class}\n",
    "                \n",
    "\n",
    "        return results, errors, k_metrics_per_class, average_metrics, std_metrics\n",
    "\n",
    "    @staticmethod\n",
    "    def error(predictions, y, uses_df=False):\n",
    "        if uses_df:\n",
    "            predictions = predictions.values\n",
    "            y = y.values\n",
    "\n",
    "        return functools.reduce(\n",
    "            lambda x, y: 0 if x == y else 1, list(zip(predictions, y)), 0) / len(predictions)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_confusion_matrix(y, y_pred, labels=None) -> pd.DataFrame:\n",
    "        cf_matrix = confusion_matrix(y, y_pred, labels=labels)\n",
    "        return pd.DataFrame(cf_matrix, index=labels, columns=labels)\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_confusion_matrix_heatmap(cf_matrix, predicted_title=\"Predicted label\", actual_title=\"Truth label\", plot_title=\"\"):\n",
    "        ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues', fmt='d')\n",
    "        ax.set_xlabel(predicted_title, fontsize=15)\n",
    "        ax.set_ylabel(actual_title, fontsize=15)\n",
    "        plt.yticks(rotation=0)\n",
    "        ax.xaxis.tick_top()  # x axis on top\n",
    "        ax.xaxis.set_label_position('top')\n",
    "        plt.rcParams[\"figure.figsize\"] = (8, 6)\n",
    "        plt.title(plot_title, fontsize=20)\n",
    "        plt.show()\n",
    "\n",
    "    # https://arxiv.org/pdf/2008.05756#:~:text=Accuracy%20is%20one%20of%20the,computed%20from%20the%20confusion%20matrix.&text=The%20formula%20of%20the%20Accuracy,confusion%20matrix%20at%20the%20denominator.\n",
    "    @staticmethod\n",
    "    def get_tp_for_class(cf_matrix, label):\n",
    "        return cf_matrix[label][label]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_tn_for_class(cf_matrix, label):\n",
    "        # Sum all values and subtract other metrics\n",
    "        return cf_matrix.to_numpy().sum() - \\\n",
    "            (Metrics.get_tp_for_class(cf_matrix, label) +\n",
    "             Metrics.get_fp_for_class(cf_matrix, label) +\n",
    "             Metrics.get_fn_for_class(cf_matrix, label))\n",
    "\n",
    "    @staticmethod\n",
    "    def get_fp_for_class(cf_matrix, label):\n",
    "        # Sum all rows except the label row\n",
    "        return sum(cf_matrix.loc[:, label]) - cf_matrix[label][label]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_fn_for_class(cf_matrix, label):\n",
    "        # Sum all columns except the label column\n",
    "        return sum(cf_matrix.loc[label, :]) - cf_matrix[label][label]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_accuracy_for_class(cf_matrix, label):\n",
    "        # (TP + TN) / (TP + TN + FP + FN)\n",
    "        numerator = Metrics.get_tp_for_class(\n",
    "            cf_matrix, label) + Metrics.get_tn_for_class(cf_matrix, label)\n",
    "        denominator = numerator + \\\n",
    "            Metrics.get_fp_for_class(cf_matrix, label) + \\\n",
    "            Metrics.get_fn_for_class(cf_matrix, label)\n",
    "        return numerator / denominator\n",
    "\n",
    "    @staticmethod\n",
    "    def get_precision_for_class(cf_matrix, label):\n",
    "        # TP / (TP + FP)\n",
    "        numerator = Metrics.get_tp_for_class(cf_matrix, label)\n",
    "        denominator = numerator + Metrics.get_fp_for_class(cf_matrix, label)\n",
    "        return numerator / denominator\n",
    "\n",
    "    @staticmethod\n",
    "    def get_recall_for_class(cf_matrix, label):\n",
    "        # TP / (TP + FN)\n",
    "        numerator = Metrics.get_tp_for_class(cf_matrix, label)\n",
    "        denominator = numerator + Metrics.get_fn_for_class(cf_matrix, label)\n",
    "        return numerator / denominator\n",
    "\n",
    "    @staticmethod\n",
    "    def get_f1_score_for_class(cf_matrix, label):\n",
    "        # 2 * Precision * Recall / (Precision + Recall)\n",
    "        precision = Metrics.get_precision_for_class(cf_matrix, label)\n",
    "        recall = Metrics.get_recall_for_class(cf_matrix, label)\n",
    "        return 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_tp_rate_for_class(cf_matrix, label):\n",
    "        # TP / (TP + FN)\n",
    "        return Metrics.get_recall_for_class(cf_matrix, label)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_fp_rate_for_class(cf_matrix, label):\n",
    "        # FP / (FP + TN)\n",
    "        numerator = Metrics.get_fp_for_class(cf_matrix, label)\n",
    "        denominator = numerator + Metrics.get_tn_for_class(cf_matrix, label)\n",
    "        return numerator / denominator\n",
    "\n",
    "    @staticmethod\n",
    "    def get_metrics_per_class(cf_matrix) -> Tuple[dict, pd.DataFrame]:\n",
    "        metrics = {}\n",
    "        for label in cf_matrix.columns:\n",
    "            metrics[label] = {\n",
    "                'accuracy': Metrics.get_accuracy_for_class(cf_matrix, label),\n",
    "                'precision': Metrics.get_precision_for_class(cf_matrix, label),\n",
    "                'recall': Metrics.get_recall_for_class(cf_matrix, label),\n",
    "                'f1-score': Metrics.get_f1_score_for_class(cf_matrix, label),\n",
    "                'tp-rate': Metrics.get_tp_rate_for_class(cf_matrix, label),\n",
    "                'fp-rate': Metrics.get_fp_rate_for_class(cf_matrix, label)\n",
    "            }\n",
    "\n",
    "        # Build a dataframe from the metrics dictionary\n",
    "        df = pd.DataFrame.from_dict(metrics, orient='index')\n",
    "        return metrics, df\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_roc_confusion_matrix_for_class(model, x, y, label, threshold):\n",
    "        y_expected = []\n",
    "        y_predicted = []\n",
    "        for x_sample, y_sample in zip(x, y):\n",
    "            # Classify sample to True or False depending on threshold\n",
    "            y_pred_class = Metrics.get_prediction_for_class_with_threshold(\n",
    "                model, x_sample, label, threshold)\n",
    "\n",
    "            # Get y sample class as True or False\n",
    "            y_sample_class = str(y_sample == label)\n",
    "\n",
    "            # Add to arrays\n",
    "            y_expected.append(y_sample_class)\n",
    "            y_predicted.append(y_pred_class)\n",
    "\n",
    "        # Get confusion matrix\n",
    "        cf_matrix = Metrics.get_confusion_matrix(\n",
    "            y_expected, y_predicted, labels=[\"True\", \"False\"])\n",
    "        return cf_matrix\n",
    "\n",
    "    @staticmethod\n",
    "    def get_prediction_for_class_with_threshold(model, x, label, threshold):\n",
    "        y_pred = model.classify(x, label=label)\n",
    "        # If prediction is above threshold, return True\n",
    "        return str(y_pred >= threshold)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_tp_and_fp_rate_cf_matrix_by_class(cf_matrix, label) -> Tuple[float, float]:\n",
    "        tp = Metrics.get_tp_rate_for_class(cf_matrix, label)\n",
    "        fp = Metrics.get_fp_rate_for_class(cf_matrix, label)\n",
    "        return tp, fp\n",
    "\n",
    "    @staticmethod\n",
    "    def get_roc_curve_for_class(model, x, y, label, thresholds: list[float]) -> Tuple[list[float], list[float]]:\n",
    "        y_tp_rates = []\n",
    "        x_fp_rates = []\n",
    "\n",
    "        for threshold in thresholds:\n",
    "            cf_matrix = Metrics.get_roc_confusion_matrix_for_class(\n",
    "                model, x, y, label, threshold)\n",
    "            tp, fp = Metrics.get_tp_and_fp_rate_cf_matrix_by_class(\n",
    "                cf_matrix, \"True\")\n",
    "            y_tp_rates.append(tp)\n",
    "            x_fp_rates.append(fp)\n",
    "\n",
    "        return x_fp_rates, y_tp_rates\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_roc_curves(model, x, y, labels: list[str], thresholds: list[float]) -> list[pd.DataFrame]:\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "\n",
    "        roc_curves_df = []\n",
    "\n",
    "        for label in labels:\n",
    "            x_fp_rates, y_tp_rates = Metrics.get_roc_curve_for_class(\n",
    "                model, x, y, label, thresholds)\n",
    "\n",
    "            # Plot a smooth ROC curve\n",
    "            auc_score = Metrics.get_roc_auc_score(x_fp_rates, y_tp_rates)\n",
    "            plt.plot(x_fp_rates, y_tp_rates,\n",
    "                     label=f'{label} - AUC {auc_score:.5f}', marker='o')\n",
    "\n",
    "            # Add to dataframe\n",
    "            roc_curves_df.append(pd.DataFrame([x_fp_rates, y_tp_rates], index=[\n",
    "                                 'FP', 'TP'], columns=thresholds))\n",
    "\n",
    "        # Plot ROC curve\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "        plt.legend(fontsize=15)\n",
    "        plt.xlabel('FP Rate', fontsize=20)\n",
    "        plt.ylabel('TP Rate', fontsize=20)\n",
    "        plt.show()\n",
    "\n",
    "        return roc_curves_df\n",
    "\n",
    "    @staticmethod\n",
    "    def get_roc_auc_score(x_fp_rates, y_tp_rates):\n",
    "        return auc(x_fp_rates, y_tp_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, name, parents, states):\n",
    "        self.name = name\n",
    "        self.parents = parents\n",
    "        self.states = states\n",
    "\n",
    "    def set_probabilities_table(self, probabilities_table):\n",
    "        self.probabilities_table = probabilities_table\n",
    "\n",
    "def get_child_probabilities_table(data_df, parents_node_names, child_node_name):\n",
    "    return data_df.groupby(parents_node_names + [child_node_name]).size()/ len(data_df.groupby(parents_node_names + [child_node_name]).size())\n",
    "\n",
    "def categorize_column(data_df, column_name, categories):\n",
    "    for index, category in enumerate(categories[:-1]):\n",
    "        data_df.loc[(data_df[column_name] >= category[\"floor\"]) & (\n",
    "            data_df[column_name] < category[\"ceiling\"]), column_name + ' category'] = str(index)\n",
    "\n",
    "    data_df.loc[data_df[column_name] >=\n",
    "                            categories[-1][\"floor\"], column_name + ' category'] = str(len(categories)-1)\n",
    "\n",
    "    return data_df\n",
    "\n",
    "\n",
    "def get_simple_probabilities_table(data_df, node):\n",
    "    # el nodo tiene un unico padre\n",
    "    groupby_df = data_df.groupby(list(map(lambda n: n.name, node.parents))+[node.name]).size().reset_index(name=\"appearances\")\n",
    "    groupby_df[node.name] = groupby_df[node.name].astype(int) # no puedo evitar esto\n",
    "    probabilities_table = pd.DataFrame(columns=[node.parents[0].name, node.name, \"frequency\"])\n",
    "    possible_states = list(itertools.product(node.parents[0].states, node.states)) \n",
    "    #para que el estado del nodo actual este al final lo agrego ultimo\n",
    "    \n",
    "    for i, state in enumerate(possible_states):\n",
    "        try:\n",
    "            parent_state_appearances_df = groupby_df.loc[(groupby_df[node.parents[0].name] == state[0])]\n",
    "            parent_state_appearances = parent_state_appearances_df[\"appearances\"].sum()\n",
    "        except: parent_state_appearances = 0\n",
    "\n",
    "        try:\n",
    "            node_state_appearances = parent_state_appearances_df.loc[(parent_state_appearances_df[node.name] == state[1])][\"appearances\"].values[0]\n",
    "        except: node_state_appearances = 0\n",
    "\n",
    "        probabilities_table.loc[i] =  list(state)+[(node_state_appearances+1)/(parent_state_appearances+len(node.states))]\n",
    "\n",
    "    #print(probabilities_table)\n",
    "    return probabilities_table\n",
    "\n",
    "def get_3parents_probabilities_table(data_df, node):\n",
    "    groupby_df = data_df.groupby(list(map(lambda n: n.name, node.parents))+[node.name]).size().reset_index(name=\"appearances\")\n",
    "    groupby_df[node.name] = groupby_df[node.name].astype(int) # no puedo evitar esto\n",
    "    groupby_df[node.parents[0].name] = groupby_df[node.parents[0].name].astype(int) # no puedo evitar esto\n",
    "    groupby_df[node.parents[1].name] = groupby_df[node.parents[1].name].astype(int) # no puedo evitar esto\n",
    "    groupby_df[node.parents[2].name] = groupby_df[node.parents[2].name].astype(int) # no puedo evitar esto\n",
    "    \n",
    "    probabilities_table = pd.DataFrame(columns=list(map(lambda n: n.name, node.parents)) + [node.name, \"frequency\"])\n",
    "    parents_states = list(map(lambda x: x.states, node.parents))\n",
    "    possible_states = list(itertools.product(*parents_states, node.states)) \n",
    "    #para que el estado del nodo actual este al final lo agrego ultimo\n",
    "\n",
    "    for i, state in enumerate(possible_states):\n",
    "\n",
    "        try:\n",
    "            parent_state_appearances_df = groupby_df.loc[(groupby_df[node.parents[0].name] == state[0])& \\\n",
    "            (groupby_df[node.parents[1].name] == state[1]) & \\\n",
    "            (groupby_df[node.parents[2].name] == state[2])]\n",
    "            parent_state_appearances = parent_state_appearances_df[\"appearances\"].sum()\n",
    "        except: parent_state_appearances = 0\n",
    "\n",
    "        try:\n",
    "            node_state_appearances = parent_state_appearances_df.loc[(parent_state_appearances_df[node.name] == state[3])][\"appearances\"].values[0]\n",
    "        except: node_state_appearances = 0\n",
    "        \n",
    "        probabilities_table.loc[i] =  list(state)+[(node_state_appearances+1)/(parent_state_appearances+len(node.states))]\n",
    "\n",
    "    #print(probabilities_table)\n",
    "    return probabilities_table\n",
    "\n",
    "def classify_complete_sample(sample, leaf_node):\n",
    "    frequencies_df = leaf_node.probabilities_table.loc[\n",
    "            (leaf_node.probabilities_table[\"rank\"] == sample[0]) & \\\n",
    "            (leaf_node.probabilities_table[\"gre category\"] == sample[1]) & \\\n",
    "            (leaf_node.probabilities_table[\"gpa category\"] == sample[2])\n",
    "            ]\n",
    "\n",
    "    return frequencies_df.loc[frequencies_df[\"frequency\"].idxmax()][\"admit\"], frequencies_df.loc[frequencies_df[\"frequency\"].idxmax()][\"frequency\"]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"./binary.csv\", header=0)\n",
    "GRE_CATEGORY =[{\n",
    "    \"floor\": 0,\n",
    "    \"ceiling\": 500\n",
    "},{\n",
    "    \"floor\": 500,\n",
    "}]\n",
    "data_df = categorize_column(data_df, \"gre\", GRE_CATEGORY)\n",
    "GPA_CATEGORY =[{\n",
    "    \"floor\": 0,\n",
    "    \"ceiling\": 3\n",
    "},{\n",
    "    \"floor\": 3,\n",
    "}]\n",
    "data_df = categorize_column(data_df, \"gpa\", GPA_CATEGORY)\n",
    "\n",
    "folds = Metrics.k_fold_cross_validation(data_df.values.tolist(), data_df[\"admit\"].values.tolist(),\\\n",
    "     x_column_names = data_df.columns, y_column_names= [\"admit\"], k=10, folds_to_return=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# PARA METRICAS!\n",
    "data_df = folds[0][\"x_train\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Caso root: RANK\n",
    "ROOT_CATEGORY = [1,2,3,4]\n",
    "ranks_count_df = data_df.groupby([\"rank\"]).size().reset_index(name=\"appearances\")\n",
    "ranks_count_df[\"rank\"] = ranks_count_df[\"rank\"].astype(int) # no puedo evitar esto\n",
    "ranks_frequency = pd.DataFrame(columns=[\"rank\", \"frequency\"])\n",
    "for index, rank in enumerate(ROOT_CATEGORY):\n",
    "    ranks_frequency.loc[index] = \\\n",
    "        [rank, ranks_count_df.loc[ranks_count_df[\"rank\"] == rank][\"appearances\"].values[0]/len(data_df)]\n",
    "\n",
    "root_node = Node(\"rank\", None, ROOT_CATEGORY)\n",
    "#print(ranks_frequency)\n",
    "root_node.set_probabilities_table(ranks_frequency)\n",
    "\n",
    "# Caso 1: GRE\n",
    "gre_node = Node(\"gre category\", [root_node], list(range(len(GRE_CATEGORY))))\n",
    "\n",
    "gre_frequency = get_simple_probabilities_table(data_df, gre_node)\n",
    "gre_node.set_probabilities_table(gre_frequency)\n",
    "\n",
    "# Caso 2: GPA\n",
    "gpa_node = Node(\"gpa category\", [root_node], list(range(len(GPA_CATEGORY))))\n",
    "gpa_frequency = get_simple_probabilities_table(data_df, gpa_node)\n",
    "gpa_node.set_probabilities_table(gpa_frequency)\n",
    "\n",
    "admit_node = Node(\"admit\", [root_node, gre_node, gpa_node], [0,1])\n",
    "admit_frequency = get_3parents_probabilities_table(data_df, admit_node)\n",
    "admit_node.set_probabilities_table(admit_frequency)\n",
    "#print(admit_frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob no admitido:  0.4591269841269841\n",
      "prob admitido:  (0.0, 0.8095238095238095)\n"
     ]
    }
   ],
   "source": [
    "# a) Calcular la probabilidad de que una persona que proviene de una escuela con rango 1 no haya sido admitida en la universidad.\n",
    "numerator = 0\n",
    "for i, gpa_state in enumerate(gpa_node.states):\n",
    "    for j, gre_state in enumerate(gre_node.states):\n",
    "        # Usando teorema de la factorizacion de la probabilidad\n",
    "        numerator += \\\n",
    "            admit_node.probabilities_table.loc[\n",
    "            (admit_node.probabilities_table[\"rank\"] == 1) & \\\n",
    "            (admit_node.probabilities_table[\"gpa category\"] == gpa_state) & \\\n",
    "            (admit_node.probabilities_table[\"gre category\"] == gre_state) & \\\n",
    "            (admit_node.probabilities_table[\"admit\"] == 0)][\"frequency\"].values[0] * \\\n",
    "                \\\n",
    "            gpa_node.probabilities_table.loc[\n",
    "            (gpa_node.probabilities_table[\"rank\"] == 1) & \\\n",
    "                (gpa_node.probabilities_table[\"gpa category\"] == gpa_state)][\"frequency\"].values[0] * \\\n",
    "                \\\n",
    "            gre_node.probabilities_table.loc[\n",
    "            (gre_node.probabilities_table[\"rank\"] == 1) & \\\n",
    "                (gre_node.probabilities_table[\"gre category\"] == gre_state)][\"frequency\"].values[0] * \\\n",
    "                \\\n",
    "            root_node.probabilities_table.loc[\n",
    "            (root_node.probabilities_table[\"rank\"] == 1)][\"frequency\"].values[0]\n",
    "\n",
    "denominator = root_node.probabilities_table.loc[\n",
    "            (root_node.probabilities_table[\"rank\"] == 1)]['frequency'][0]\n",
    "            \n",
    "print(\"prob no admitido: \", numerator/denominator)\n",
    "\n",
    "# b) Calcular la probabilidad de que una persona que proviene de una escuela con rango 2, GPA 1 y GRE 0 haya sido admitida en la universidad.\n",
    "prob_admitted = classify_complete_sample([2,1,0], admit_node)\n",
    "print(\"prob admitido: \", prob_admitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:      0  1\n",
      "0  31  3\n",
      "1   5  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy  precision    recall  f1-score   tp-rate   fp-rate\n",
      "0       0.8   0.861111  0.911765  0.885714  0.911765  0.833333\n",
      "1       0.8   0.250000  0.166667  0.200000  0.166667  0.088235\n"
     ]
    }
   ],
   "source": [
    "# Classify test data\n",
    "y_pred = []\n",
    "for row_idx in range(len(folds[0][\"x_test\"])):\n",
    "    row = folds[0][\"x_test\"].iloc[[row_idx]]\n",
    "    sample = list(map(int,[row[\"rank\"].values[0],\\\n",
    "        row[\"gre category\"].values[0],\\\n",
    "            row[\"gpa category\"].values[0]]))\n",
    "    ans = classify_complete_sample(sample, admit_node)\n",
    "    y_pred.append(ans[0])\n",
    "\n",
    "cf_matrix = Metrics.get_confusion_matrix(folds[0][\"y_test\"].values.tolist(), y_pred, [0,1])\n",
    "print(\"Accuracy: \", cf_matrix)\n",
    "heat_map = Metrics.plot_confusion_matrix_heatmap(cf_matrix)\n",
    "\n",
    "df = Metrics.get_metrics_per_class(cf_matrix)[1]\n",
    "df.to_csv(\"./dump/metrics.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
